<!doctype html><html lang=en-us><head><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="[!NOTE] Moved here from src/lib/score.jl in GlobalBrain.jl.
weight returns a score for determining the top comment for purposes of calculating the informed probability of the post. It is a measure of how much the critical thread that starts with that comment changes the probability of upvoting the post."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.131.0"><title>- Social Protocols</title>
<meta property="og:title" content=" - Social Protocols"><link rel=stylesheet href=/css/fonts.css media=all><link rel=stylesheet href=/css/main.css media=all><script data-goatcounter=https://socialprotocols.goatcounter.com/count async src=//gc.zgo.at/count.js></script></head><body><div class=wrapper><header class=header><nav class=nav><a href=/ class=nav-logo style=margin-right:10px><img src=/images/logo.svg width=50 height=50 alt=Logo>
</a><a href=/ class=nav-title>Social Protocols</a><ul class=nav-links><li><a href=/articles>Articles</a></li><li><a href=/#projects>Projects</a></li><li><a href=/research-notes>Research Notes</a></li><li><a href=/resources>Resources</a></li></ul></nav></header><main class=content role=main><article class=article><h1 class=article-title></h1><div class=article-content><blockquote><p>[!NOTE]
Moved here from <code>src/lib/score.jl</code> in <code>GlobalBrain.jl</code>.</p></blockquote><p>weight returns a score for determining the top comment for purposes of
calculating the informed probability of the post. It is a measure of how
much the <em>critical thread that starts with that comment</em> changes the probability of
upvoting the post.</p><p>ranking_score returns a score for determining how much attention a post
should receive &ndash; the value of a user considering that particular post.</p><p>These are different values. To understand the difference, suppose we have
posts A->B->C, P(A|not B, not C) = 10%, P(A|B, not C)=90%, and P(A|B,C) =
15%. So C mostly erases the effect of B on A. The effect of B is p=15%
(fully informed), q=10%(uninformed), and r=90% (partially informed).</p><p>So B, without C, makes users <em>less</em> informed! If users only consider B and
not C, their upvote probability is r=90%, which is further from the
informed probability p=15% then where we started at q=10%. This means
considering B and not C only increases cognitive dissonance.</p><p>Cognitive dissonance before considering B:</p><p>relative_entropy(p, q) = relative_entropy(.15, .10) = .0176</p><p>Cognitive dissonance after considering B:</p><p>relative_entropy(p, r) = relative_entropy(.15, .9) = 2.2366</p><p>So for purposes of ranking, B has <em>negative</em> information value, because
considering B without considering C actually makes users more uninformed!
The information value of B (without C) is</p><p>information_gain(p,r,q)
= relative_entropy(p, q) - relative_entropy(p, r)
= .0176 - 2.2366
= -2.2189.</p><p>On the other hand, for purposes of calculating the informed probability of
A, the most informed thread may be: A->B->C. The relative entropy for the
thread is:</p><p>relative_entropy(p, q) = relative_entropy(.15, .1) = .0176</p><p>So unless there are threads with higher scores, B might be the start of the
most informative thread, even though B as a post has negative information
value.</p><p>We multiple weight by p_size as a heuristic to deal with duplicates.
Suppose we have the same posts A->B->C. Before C is submitted, the informed
probability of A will be close to 90%. However, C will reduce the this
significantly to 15%.</p><p>At this point, a user could submit a near duplicate of B, B&rsquo;, and before
somebody submitted a duplicate of comment C, C&rsquo;, B&rsquo; would become the top comment
and the informed probability of A will bounce back up to 90%.</p><p>Multiplying weight by p_size is a heuristic that kinds of deals with
this. We give more weight to comments that have had more attention, and
therefore have been exposed to more scrutiny and there is therefore a
greater chance of users responding with a counter argument. So at first,
even though B&rsquo; has a high relative_entropy, it has a low score because its
p_size is low. As its p_size increases, the probability that somebody
responds with C&rsquo; increases.</p><p>If people keep on submitting duplicates, users should start to notice and
start downvoting the duplicates, so that they never receive enough
attention to become the top comment and people don&rsquo;t have to respond to them.
Code for generating above calculations:
p = .15
q = .1
r = .9
GlobalBrain.relative_entropy(p, q)
GlobalBrain.relative_entropy(p, r)
GlobalBrain.information_gain(p, q, r)
GlobalBrain.relative_entropy(p, q) - GlobalBrain.relative_entropy(p, r)</p></div></article></main><footer class=footer><ul class=footer-links><li><a href type=application/rss+xml target=_blank>RSS</a></li><li><a href=https://github.com/social-protocols>GitHub</a></li><li><a href=https://mas.to/@SocialProtocols>Mastodon</a></li><li><a href=https://medium.com/@socialprotocols>Medium</a></li><li><a href=https://socialprotocols.substack.com>Substack</a></li><li><a href=https://twitter.com/socialprotocols>Twitter</a></li><li><a href=https://social-protocols.zulipchat.com/join/3awvls77dbmolwlradnfmkig/>Zulip</a></li></ul></footer></div></body></html>