---
title: "Every Minute of Hacker News"
description: |
  A dataset of every minute of Hacker News over a period of several months.
# author:
#   - name: Nora Jones 
#     url: https://example.com/norajones
#     affiliation: Spacely Sprockets
#     affiliation_url: https://example.com/spacelysprokets
date: "`r Sys.Date()`"
output: distill::distill_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


[Hacker News](news.ycombinator.com) is a social news aggregator provided by the US startup accelerator [Y Combinator](ycombinator.com).
On Hacker News, users submit stories^[links to content anywhere on the Internet] that are then subject to voting by the community.
The main news aggregation happens on the *top* page (or frontpage) of HN, where content is scored and ranked according to the [following formula](http://www.righto.com/2013/11/how-hacker-news-ranking-really-works.html):

$$
score = \frac{(votes - 1)^{0.8}}{(age_{hours} + 2)^{1.8}} \times penalties
$$

While *top* is the most prominent page on HN, there are [other ranked pages](https://news.ycombinator.com/lists) as well.

The kind of content posted on HN as well as the ranking on the top page is determined by the preferences of the community because all content as well as the voting is user-generated.
There is a loose [guideline](https://news.ycombinator.com/newsguidelines.html) for what is considered *on-topic*:

> Anything that good hackers would find interesting. That includes more than hacking and startups. If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity.

Apart from posting stories, voting, and browsing the top lists, users can have discussions in comment threads under each story.

Our motivation for collecting a dataset on Hacker News was [an investigation](https://felx.me/2021/08/29/improving-the-hacker-news-ranking-algorithm.html) into feedback loops in the current ranking scheme.
In short, our argument was that stories that are picked up by a positive feedback loop of attention and votes spiral upwards in the ranking while many "hidden gems" go unnoticed.
In order to test our ideas for new ranking algorithms that counter this feedback loop, we first tried to recreate Hacker News as close as possible in a [simulation](https://github.com/social-protocols/news-aggregator-simulation) that is [still available](https://social-protocols.github.io/news-aggregator-simulation/) for experimentation in the browser.
We soon realized that we need data to verify and benchmark how far off we were with our simulation.


### Data Collection

Y Combinator provides access to a [BigQuery database](https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news) where all stories since the launch of Hacker News are available.
This database contains all the *outcomes* of Hacker News stories, but **not** how stories developed **towards** those outcomes.

In order to attain a timeseries of snapshots of the most popular ranking lists on Hacker News, we queried the [Hacker News API](https://github.com/HackerNews/API) in 1 minute intervals over a period of over 4 months.
We started the data collection on `2021-11-23 23:10:07` and ended it on `2022-04-03 14:07:24`.
In total, we tracked 110556 stories, of which 103961 were tracked over their entire lifecycle^[For our definition of a story's full lifecycle, refer to [this SQL query](https://github.com/social-protocols/hacker-news-data/blob/f24c8ff6438921ee628a7b9f069c622830e2e5eb/import-dataset.sql#L60)].
The scraper we used is available on [Github](https://github.com/social-protocols/hn-scraper).
It collected data in the following way:

- Get the first 90 ranks of the `top`, `new`, `best`, `ask`, `show`, and `job` page as ordered lists of IDs.
- Get additional data on each story that appears on any of the above lists.
- Create an entry for each story in the dataset, containing its rank on each list^[`\N` if it does not appear on the list in question.] as well as the additional information.


### The Dataset

Overall, the dataset has `67,266,751` rows with an entry for each of the following fields:

- `id`: The item ID assigned by HN. Almost everything on HN is an item, e.g., stories, comments, jobs, ... However, the dataset only contains *stories* as we only scraped the top lists.
- `score`: This name is slightly misleading: `score` designate the raw *vote count* of the item, not the score obtained from the above mentioned formula. We left the name as is because the HN API delivers it with this name.
- `descendants`: The number of comments (including comments of comments of comment...).
- `submissionTime`: A timestamp of the time the story was submitted in Unix epoch format.
- `sampleTime`: The time when the scraper collected the data point (also as a Unix epoch timestamp).
- `tick`: A running number of the `sampleTime`s.
- `topRank`: The current rank on the `top` page (up to rank 90, otherwise `\N`; this is true for all other collected ranks too).
- `newRank`: The current rank on the `new` page.
- `bestRank`: The current rank on the `best` page.
- `askRank`: The current rank on the `ask` page.
- `showRank`: The current rank on the `show` page.
- `jobRank`: The current rank on the `jobs` page.
- `gain`: Votes gained since the last `sampleTime`.

The full dataset is stored in `tsv` format and compressed as a `7z` archive.
It is available on the [open science framework](https://osf.io/bnysw/).
You can download it from there, for example like this:

```
$ wget --no-verbose --show-progress https://osf.io/h9sjy/download -O hacker-news.7z
```


### Exploratory Analysis

You can view many of our analyses on this dataset [on Github](https://github.com/social-protocols/hacker-news-data), but we would be happy to see what new insights you can draw from the data.

(ADD SOME EXPLORATORY INSIGHTS/PLOTS ETC.)
